{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import date\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier,ExtraTreesClassifier,AdaBoostClassifier\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Activation\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from six.moves import cPickle as pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv('train.csv')\n",
    "test=pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df43 = pd.DataFrame(data, columns = ['genre_id', 'is_listened'])\n",
    "df45 = pd.DataFrame(data, columns = ['media_id', 'is_listened'])\n",
    "df46=  pd.DataFrame(data, columns = ['album_id', 'is_listened'])\n",
    "df47=  pd.DataFrame(data, columns = ['artist_id', 'is_listened'])\n",
    "df51=  pd.DataFrame(data, columns = ['user_id', 'is_listened'])\n",
    "df53=  pd.DataFrame(data, columns = ['release_date', 'is_listened'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TO create fractional features. First groupby ids and then calculate mean of is listened for every level of id\n",
    "#and then map it on data using dictionary creation\n",
    "count1=df43.groupby(['genre_id'],as_index=False).agg({'is_listened':'mean'})\n",
    "df44=pd.Series(count1.is_listened.values,index=count1.genre_id).to_dict()\n",
    "data[\"B\"] = data[\"genre_id\"].map(df44)\n",
    "test[\"B\"] = test[\"genre_id\"].map(df44)\n",
    "\n",
    "\n",
    "count2=df45.groupby(['media_id'],as_index=False).agg({'is_listened':'mean'})\n",
    "df48=pd.Series(count2.is_listened.values,index=count2.media_id).to_dict()\n",
    "data[\"C\"] = data[\"media_id\"].map(df48)\n",
    "test[\"C\"] = test[\"media_id\"].map(df48)\n",
    "\n",
    "count3=df46.groupby(['album_id'],as_index=False).agg({'is_listened':'mean'})\n",
    "df49=pd.Series(count3.is_listened.values,index=count3.album_id).to_dict()\n",
    "data[\"D\"] = data[\"album_id\"].map(df49)\n",
    "test[\"D\"] = test[\"album_id\"].map(df49)\n",
    "data.head()\n",
    "count4=df47.groupby(['artist_id'],as_index=False).agg({'is_listened':'mean'})\n",
    "df50=pd.Series(count4.is_listened.values,index=count4.artist_id).to_dict()\n",
    "data[\"E\"] = data[\"artist_id\"].map(df50)\n",
    "test[\"E\"] = test[\"artist_id\"].map(df50)\n",
    "\n",
    "count5=df51.groupby(['user_id'],as_index=False).agg({'is_listened':'mean'})\n",
    "df52=pd.Series(count5.is_listened.values,index=count5.user_id).to_dict()\n",
    "data[\"F\"] = data[\"user_id\"].map(df52)\n",
    "test[\"F\"] = test[\"user_id\"].map(df52)\n",
    "\n",
    "count6=df53.groupby(['release_date'],as_index=False).agg({'is_listened':'mean'})\n",
    "df54=pd.Series(count6.is_listened.values,index=count6.release_date).to_dict()\n",
    "data[\"G\"] = data[\"release_date\"].map(df54)\n",
    "test[\"G\"] = test[\"release_date\"].map(df54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del count1\n",
    "del count2\n",
    "del count3\n",
    "del count4\n",
    "del count5\n",
    "del count6\n",
    "del df43\n",
    "del df44\n",
    "del df45\n",
    "del df46\n",
    "del df47\n",
    "del df48\n",
    "del df49\n",
    "del df50\n",
    "del df51\n",
    "del df52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:05:53.485949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/pandas/core/indexing.py:179: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:02:40.903218\n",
      "0:04:22.317093\n",
      "0:02:51.561791\n",
      "0:00:53.092824\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.datetime.now()\n",
    "#pivot table for clustering of similar users. Till now only used genre id for cluster\n",
    "matrix = data.pivot_table(index=['user_id'], columns=['genre_id'], values='is_listened')\n",
    "cluster = KMeans(n_clusters=50)\n",
    "matrix=matrix.fillna(0)\n",
    "x_cols = matrix.columns[1:]\n",
    "#the below line is server specific and is used to predict cluster of users and then we have mapped users on clusters\n",
    "matrix['cluster'] = cluster.fit_predict(matrix[matrix.columns[1:]])\n",
    "#matrix1=pd.concat([matrix.iloc[:,0],matrix['cluster']],axis=1)\n",
    "matrix1=pd.concat([pd.DataFrame(matrix.index.values),matrix['cluster']],axis=1)\n",
    "matrix1.columns=['user_id','cluster']\n",
    "mat2=pd.Series(matrix1.cluster.values,index=matrix1.user_id.values).to_dict()\n",
    "data[\"usergencluster\"] = data[\"user_id\"].map(mat2)\n",
    "test[\"usergencluster\"]=test[\"user_id\"].map(mat2)\n",
    "print(datetime.datetime.now()-start_time)\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "data['album_id_1']=data['album_id']\n",
    "test['album_id_1']=test['album_id']\n",
    "mmo3=pd.DataFrame(data['album_id_1'].value_counts())\n",
    "mmo3=pd.concat([pd.DataFrame(mmo3.index.values),pd.DataFrame(mmo3.album_id_1.values)],axis=1)\n",
    "mmo31=list(mmo3.iloc[1500:,0])\n",
    "data['album_id_1'].loc[data['album_id_1'].isin(mmo31)]=-1\n",
    "matrix = data.pivot_table(index=['user_id'], columns=['album_id_1'], values='is_listened')\n",
    "cluster = KMeans(n_clusters=50)\n",
    "matrix=matrix.fillna(0)\n",
    "#the below line is server specific and is used to predict cluster of users and then we have mapped users on clusters\n",
    "matrix['cluster'] = cluster.fit_predict(matrix[matrix.columns[1:]])\n",
    "#matrix1=pd.concat([matrix.iloc[:,0],matrix['cluster']],axis=1)\n",
    "matrix1=pd.concat([pd.DataFrame(matrix.index.values),matrix['cluster']],axis=1)\n",
    "matrix1.columns=['user_id','cluster']\n",
    "mat2=pd.Series(matrix1.cluster.values,index=matrix1.user_id.values).to_dict()\n",
    "data[\"useralbcluster\"] = data[\"user_id\"].map(mat2)\n",
    "test[\"useralbcluster\"]=test[\"user_id\"].map(mat2)\n",
    "del matrix\n",
    "del matrix1\n",
    "del mat2\n",
    "print(datetime.datetime.now()-start_time)\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "data['media_id_1']=data['media_id']\n",
    "test['media_id_1']=test['media_id']\n",
    "mmo3=pd.DataFrame(data['media_id_1'].value_counts())\n",
    "mmo3=pd.concat([pd.DataFrame(mmo3.index.values),pd.DataFrame(mmo3.media_id_1.values)],axis=1)\n",
    "mmo31=list(mmo3.iloc[3000:,0])\n",
    "data['media_id_1'].loc[data['media_id_1'].isin(mmo31)]=-1\n",
    "matrix = data.pivot_table(index=['user_id'], columns=['media_id_1'], values='is_listened')\n",
    "cluster = KMeans(n_clusters=50)\n",
    "matrix=matrix.fillna(0)\n",
    "#the below line is server specific and is used to predict cluster of users and then we have mapped users on clusters\n",
    "matrix['cluster'] = cluster.fit_predict(matrix[matrix.columns[1:]])\n",
    "#matrix1=pd.concat([matrix.iloc[:,0],matrix['cluster']],axis=1)\n",
    "matrix1=pd.concat([pd.DataFrame(matrix.index.values),matrix['cluster']],axis=1)\n",
    "matrix1.columns=['user_id','cluster']\n",
    "mat2=pd.Series(matrix1.cluster.values,index=matrix1.user_id.values).to_dict()\n",
    "data[\"usermedcluster\"] = data[\"user_id\"].map(mat2)\n",
    "test[\"usermedcluster\"]=test[\"user_id\"].map(mat2)\n",
    "del matrix\n",
    "del matrix1\n",
    "del mat2\n",
    "print(datetime.datetime.now()-start_time)\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "data['artist_id_1']=data['artist_id']\n",
    "test['artist_id_1']=test['artist_id']\n",
    "mmo3=pd.DataFrame(data['artist_id_1'].value_counts())\n",
    "mmo3=pd.concat([pd.DataFrame(mmo3.index.values),pd.DataFrame(mmo3.artist_id_1.values)],axis=1)\n",
    "mmo31=list(mmo3.iloc[1700:,0])\n",
    "data['artist_id_1'].loc[data['artist_id_1'].isin(mmo31)]=-1\n",
    "matrix = data.pivot_table(index=['user_id'], columns=['artist_id_1'], values='is_listened')\n",
    "cluster = KMeans(n_clusters=50)\n",
    "matrix=matrix.fillna(0)\n",
    "#the below line is server specific and is used to predict cluster of users and then we have mapped users on clusters\n",
    "matrix['cluster'] = cluster.fit_predict(matrix[matrix.columns[1:]])\n",
    "#matrix1=pd.concat([matrix.iloc[:,0],matrix['cluster']],axis=1)\n",
    "matrix1=pd.concat([pd.DataFrame(matrix.index.values),matrix['cluster']],axis=1)\n",
    "matrix1.columns=['user_id','cluster']\n",
    "mat2=pd.Series(matrix1.cluster.values,index=matrix1.user_id.values).to_dict()\n",
    "data[\"userartcluster\"] = data[\"user_id\"].map(mat2)\n",
    "test[\"userartcluster\"]=test[\"user_id\"].map(mat2)\n",
    "del matrix\n",
    "del matrix1\n",
    "del mat2\n",
    "print(datetime.datetime.now()-start_time)\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "data['release_date_1']=data['release_date']\n",
    "test['release_date_1']=test['release_date']\n",
    "mmo3=pd.DataFrame(data['release_date_1'].value_counts())\n",
    "mmo3=pd.concat([pd.DataFrame(mmo3.index.values),pd.DataFrame(mmo3.release_date_1.values)],axis=1)\n",
    "mmo31=list(mmo3.iloc[1000:,0])\n",
    "data['release_date_1'].loc[data['release_date_1'].isin(mmo31)]=-1\n",
    "matrix = data.pivot_table(index=['user_id'], columns=['release_date_1'], values='is_listened')\n",
    "cluster = KMeans(n_clusters=10)\n",
    "matrix=matrix.fillna(0)\n",
    "#the below line is server specific and is used to predict cluster of users and then we have mapped users on clusters\n",
    "matrix['cluster'] = cluster.fit_predict(matrix[matrix.columns[1:]])\n",
    "#matrix1=pd.concat([matrix.iloc[:,0],matrix['cluster']],axis=1)\n",
    "matrix1=pd.concat([pd.DataFrame(matrix.index.values),matrix['cluster']],axis=1)\n",
    "matrix1.columns=['user_id','cluster']\n",
    "mat2=pd.Series(matrix1.cluster.values,index=matrix1.user_id.values).to_dict()\n",
    "data[\"userdatecluster\"] = data[\"user_id\"].map(mat2)\n",
    "test[\"userdatecluster\"]=test[\"user_id\"].map(mat2)\n",
    "del matrix\n",
    "del matrix1\n",
    "del mat2\n",
    "print(datetime.datetime.now()-start_time)\n",
    "start_time = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_pickle(\"fulldata.pickle\")\n",
    "test.to_pickle(\"fulltest.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"fulldata.pickle\")\n",
    "test = pd.read_pickle(\"fulltest.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrix = data.pivot_table(index=['user_id'], columns=['platform_family'], values='is_listened')\n",
    "cluster = KMeans(n_clusters=10)\n",
    "matrix=matrix.fillna(0)\n",
    "x_cols = matrix.columns[1:]\n",
    "matrix['cluster'] = cluster.fit_predict(matrix[matrix.columns[1:]])\n",
    "matrix1=pd.concat([pd.DataFrame(matrix.index.values),matrix['cluster']],axis=1)\n",
    "matrix1.columns=['user_id','cluster']\n",
    "mat2=pd.Series(matrix1.cluster.values,index=matrix1.user_id.values).to_dict()\n",
    "data[\"userplafamcluster\"] = data[\"user_id\"].map(mat2)\n",
    "test[\"userplafamcluster\"]=test[\"user_id\"].map(mat2)\n",
    "\n",
    "\n",
    "matrix = data.pivot_table(index=['user_id'], columns=['listen_type'], values='is_listened')\n",
    "cluster = KMeans(n_clusters=10)\n",
    "matrix=matrix.fillna(0)\n",
    "x_cols = matrix.columns[1:]\n",
    "matrix['cluster'] = cluster.fit_predict(matrix[matrix.columns[1:]])\n",
    "matrix1=pd.concat([pd.DataFrame(matrix.index.values),matrix['cluster']],axis=1)\n",
    "matrix1.columns=['user_id','cluster']\n",
    "mat2=pd.Series(matrix1.cluster.values,index=matrix1.user_id.values).to_dict()\n",
    "data[\"userlistypecluster\"] = data[\"user_id\"].map(mat2)\n",
    "test[\"userlistypecluster\"]=test[\"user_id\"].map(mat2)\n",
    "\n",
    "\n",
    "matrix = data.pivot_table(index=['user_id'], columns=['platform_name'], values='is_listened')\n",
    "cluster = KMeans(n_clusters=10)\n",
    "matrix=matrix.fillna(0)\n",
    "x_cols = matrix.columns[1:]\n",
    "matrix['cluster'] = cluster.fit_predict(matrix[matrix.columns[1:]])\n",
    "matrix1=pd.concat([pd.DataFrame(matrix.index.values),matrix['cluster']],axis=1)\n",
    "matrix1.columns=['user_id','cluster']\n",
    "mat2=pd.Series(matrix1.cluster.values,index=matrix1.user_id.values).to_dict()\n",
    "data[\"userplnamecluster\"] = data[\"user_id\"].map(mat2)\n",
    "test[\"userplnamecluster\"]=test[\"user_id\"].map(mat2)\n",
    "\n",
    "\n",
    "matrix = data.pivot_table(index=['user_id'], columns=['context_type'], values='is_listened')\n",
    "cluster = KMeans(n_clusters=10)\n",
    "matrix=matrix.fillna(0)\n",
    "x_cols = matrix.columns[1:]\n",
    "matrix['cluster'] = cluster.fit_predict(matrix[matrix.columns[1:]])\n",
    "matrix1=pd.concat([pd.DataFrame(matrix.index.values),matrix['cluster']],axis=1)\n",
    "matrix1.columns=['user_id','cluster']\n",
    "mat2=pd.Series(matrix1.cluster.values,index=matrix1.user_id.values).to_dict()\n",
    "data[\"usercontypecluster\"] = data[\"user_id\"].map(mat2)\n",
    "test[\"usercontypecluster\"]=test[\"user_id\"].map(mat2)\n",
    "\n",
    "matrix = data.pivot_table(index=['user_id'], columns=['user_age'], values='is_listened')\n",
    "cluster = KMeans(n_clusters=5)\n",
    "matrix=matrix.fillna(0)\n",
    "x_cols = matrix.columns[1:]\n",
    "matrix['cluster'] = cluster.fit_predict(matrix[matrix.columns[1:]])\n",
    "matrix1=pd.concat([pd.DataFrame(matrix.index.values),matrix['cluster']],axis=1)\n",
    "matrix1.columns=['user_id','cluster']\n",
    "mat2=pd.Series(matrix1.cluster.values,index=matrix1.user_id.values).to_dict()\n",
    "data[\"useruagecluster\"] = data[\"user_id\"].map(mat2)\n",
    "test[\"useruagecluster\"] = test[\"user_id\"].map(mat2)\n",
    "\n",
    "del matrix\n",
    "del matrix1\n",
    "del mat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/pandas/core/indexing.py:179: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "mmo3=pd.DataFrame(data['album_id'].value_counts())\n",
    "mmo3=pd.concat([pd.DataFrame(mmo3.index.values),pd.DataFrame(mmo3.album_id.values)],axis=1)\n",
    "mmo31=list(mmo3.iloc[50:,0])\n",
    "data['album_id'].loc[data['album_id'].isin(mmo31)]=-1\n",
    "test['album_id'].loc[test['album_id'].isin(mmo31)]=-1\n",
    "\n",
    "mmo4=pd.DataFrame(data['artist_id'].value_counts())\n",
    "mmo4=pd.concat([pd.DataFrame(mmo4.index.values),pd.DataFrame(mmo4.artist_id.values)],axis=1)\n",
    "mmo41=list(mmo4.iloc[50:,0])\n",
    "data['artist_id'].loc[data['artist_id'].isin(mmo41)]=-1\n",
    "test['artist_id'].loc[test['artist_id'].isin(mmo41)]=-1\n",
    "\n",
    "      \n",
    "mmo5=pd.DataFrame(data['genre_id'].value_counts())\n",
    "mmo5=pd.concat([pd.DataFrame(mmo5.index.values),pd.DataFrame(mmo5.genre_id.values)],axis=1)\n",
    "mmo51=list(mmo5.iloc[50:,0])\n",
    "data['genre_id'].loc[data['genre_id'].isin(mmo51)]=-1\n",
    "test['genre_id'].loc[test['genre_id'].isin(mmo51)]=-1\n",
    "      \n",
    "mmo6=pd.DataFrame(data['context_type'].value_counts())\n",
    "mmo6=pd.concat([pd.DataFrame(mmo6.index.values),pd.DataFrame(mmo6.context_type.values)],axis=1)\n",
    "mmo61=list(mmo6.iloc[15:,0])\n",
    "data['context_type'].loc[data['context_type'].isin(mmo61)]=-1\n",
    "test['context_type'].loc[test['context_type'].isin(mmo61)]=-1\n",
    "\n",
    "data['release_date1']=data.release_date\n",
    "test['release_date1']=test.release_date\n",
    "mmo7=pd.DataFrame(data['release_date'].value_counts())\n",
    "mmo98=pd.DataFrame(test['release_date'].value_counts())\n",
    "unmatched = set(list(mmo98.index.values))-set(list(mmo7.index.values))\n",
    "test['release_date'].loc[test['release_date'].isin(unmatched)]=-1\n",
    "mmo7=pd.concat([pd.DataFrame(mmo7.index.values),pd.DataFrame(mmo7.release_date.values)],axis=1)\n",
    "mmo71=list(mmo7.iloc[30:,0])\n",
    "data['release_date'].loc[data['release_date'].isin(mmo71)]=-1\n",
    "test['release_date'].loc[test['release_date'].isin(mmo71)]=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del mmo3\n",
    "del mmo31\n",
    "del mmo4\n",
    "del mmo5\n",
    "del mmo6\n",
    "del mmo7\n",
    "del mmo41\n",
    "del mmo51\n",
    "del mmo61\n",
    "del mmo71\n",
    "del mmo98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre_id</th>\n",
       "      <th>ts_listen</th>\n",
       "      <th>media_id</th>\n",
       "      <th>album_id</th>\n",
       "      <th>context_type</th>\n",
       "      <th>release_date</th>\n",
       "      <th>platform_name</th>\n",
       "      <th>platform_family</th>\n",
       "      <th>media_duration</th>\n",
       "      <th>listen_type</th>\n",
       "      <th>...</th>\n",
       "      <th>artist_id_1</th>\n",
       "      <th>userartcluster</th>\n",
       "      <th>release_date_1</th>\n",
       "      <th>userdatecluster</th>\n",
       "      <th>userplafamcluster</th>\n",
       "      <th>userlistypecluster</th>\n",
       "      <th>userplnamecluster</th>\n",
       "      <th>usercontypecluster</th>\n",
       "      <th>useruagecluster</th>\n",
       "      <th>release_date1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>1478104371</td>\n",
       "      <td>683078</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>542</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2076</td>\n",
       "      <td>32</td>\n",
       "      <td>20021008</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>20021008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2744</td>\n",
       "      <td>1479317140</td>\n",
       "      <td>876497</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>307</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>33</td>\n",
       "      <td>19851231</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>19851231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2744</td>\n",
       "      <td>1479546361</td>\n",
       "      <td>876497</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>307</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>19851231</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>19851231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2744</td>\n",
       "      <td>1478457729</td>\n",
       "      <td>876500</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>265</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>40</td>\n",
       "      <td>19851231</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>19851231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2744</td>\n",
       "      <td>1480448560</td>\n",
       "      <td>876504</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>356</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>40</td>\n",
       "      <td>19851231</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>19851231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   genre_id   ts_listen  media_id  album_id  context_type  release_date  \\\n",
       "0        50  1478104371    683078        -1             1            -1   \n",
       "1      2744  1479317140    876497        -1             1            -1   \n",
       "2      2744  1479546361    876497        -1             1            -1   \n",
       "3      2744  1478457729    876500        -1             1            -1   \n",
       "4      2744  1480448560    876504        -1             1            -1   \n",
       "\n",
       "   platform_name  platform_family  media_duration  listen_type      ...        \\\n",
       "0              0                0             542            1      ...         \n",
       "1              0                0             307            1      ...         \n",
       "2              0                0             307            1      ...         \n",
       "3              2                1             265            1      ...         \n",
       "4              2                1             356            1      ...         \n",
       "\n",
       "   artist_id_1  userartcluster  release_date_1  userdatecluster  \\\n",
       "0         2076              32        20021008                1   \n",
       "1           26              33        19851231                6   \n",
       "2           26              10        19851231                6   \n",
       "3           26              40        19851231                6   \n",
       "4           26              40        19851231                6   \n",
       "\n",
       "   userplafamcluster  userlistypecluster  userplnamecluster  \\\n",
       "0                  0                   5                  1   \n",
       "1                  0                   7                  1   \n",
       "2                  0                   8                  1   \n",
       "3                  7                   5                  8   \n",
       "4                  8                   0                  3   \n",
       "\n",
       "   usercontypecluster  useruagecluster  release_date1  \n",
       "0                   7                0       20021008  \n",
       "1                   8                4       19851231  \n",
       "2                   8                1       19851231  \n",
       "3                   3                0       19851231  \n",
       "4                   5                3       19851231  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target=data['is_listened']\n",
    "del data['is_listened']\n",
    "test2=test.iloc[:,1:]\n",
    "data.head()\n",
    "test2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test2.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7578752, 35)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.concat([data,test2],axis=0)\n",
    "data=data.fillna(0)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummie1 = pd.get_dummies(data['context_type'], prefix='context_type', prefix_sep='_')\n",
    "dummie2 = pd.get_dummies(data['platform_name'], prefix='platform_name', prefix_sep='_')\n",
    "dummie3 = pd.get_dummies(data['platform_family'], prefix='platform_family', prefix_sep='_')\n",
    "dummie4 = pd.get_dummies(data['listen_type'], prefix='listen_type', prefix_sep='_')\n",
    "dummie5 = pd.get_dummies(data['user_gender'], prefix='user_gender', prefix_sep='_')\n",
    "dummie6 = pd.get_dummies(data['genre_id'], prefix='genre_id', prefix_sep='_')\n",
    "dummie7 = pd.get_dummies(data['album_id'], prefix='album_id', prefix_sep='_')\n",
    "dummie8 = pd.get_dummies(data['release_date'], prefix='album_id', prefix_sep='_')\n",
    "dummie9 = pd.get_dummies(data['usergencluster'], prefix='usergencluster', prefix_sep='_')\n",
    "dummie10 = pd.get_dummies(data['artist_id'], prefix='artist_id', prefix_sep='_')\n",
    "dummie11 = pd.get_dummies(data['usermedcluster'], prefix='usermedcluster', prefix_sep='_')\n",
    "dummie12= pd.get_dummies(data['useralbcluster'], prefix='useralbcluster', prefix_sep='_')\n",
    "dummie13= pd.get_dummies(data['userartcluster'], prefix='userartcluster', prefix_sep='_')\n",
    "dummie14= pd.get_dummies(data['userdatecluster'], prefix='userdatecluster', prefix_sep='_')\n",
    "dummie15 = pd.get_dummies(data['userplafamcluster'], prefix='userplafamcluster', prefix_sep='_')\n",
    "dummie16= pd.get_dummies(data['userlistypecluster'], prefix='userlistypecluster', prefix_sep='_')\n",
    "dummie17= pd.get_dummies(data['userplnamecluster'], prefix='userplnamecluster', prefix_sep='_')\n",
    "dummie18= pd.get_dummies(data['usercontypecluster'], prefix='usercontypecluster', prefix_sep='_')\n",
    "dummie19= pd.get_dummies(data['useruagecluster'], prefix='useruagecluster', prefix_sep='_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre_id</th>\n",
       "      <th>ts_listen</th>\n",
       "      <th>media_id</th>\n",
       "      <th>album_id</th>\n",
       "      <th>context_type</th>\n",
       "      <th>release_date</th>\n",
       "      <th>platform_name</th>\n",
       "      <th>platform_family</th>\n",
       "      <th>media_duration</th>\n",
       "      <th>listen_type</th>\n",
       "      <th>...</th>\n",
       "      <th>usercontypecluster_5</th>\n",
       "      <th>usercontypecluster_6</th>\n",
       "      <th>usercontypecluster_7</th>\n",
       "      <th>usercontypecluster_8</th>\n",
       "      <th>usercontypecluster_9</th>\n",
       "      <th>useruagecluster_0</th>\n",
       "      <th>useruagecluster_1</th>\n",
       "      <th>useruagecluster_2</th>\n",
       "      <th>useruagecluster_3</th>\n",
       "      <th>useruagecluster_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25471</td>\n",
       "      <td>1480597215</td>\n",
       "      <td>222606</td>\n",
       "      <td>-1</td>\n",
       "      <td>12</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>223</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>1480544735</td>\n",
       "      <td>250467</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>171</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>1479563953</td>\n",
       "      <td>305197</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>1480152098</td>\n",
       "      <td>900502</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>1478368974</td>\n",
       "      <td>542335</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 683 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   genre_id   ts_listen  media_id  album_id  context_type  release_date  \\\n",
       "0     25471  1480597215    222606        -1            12            -1   \n",
       "1        -1  1480544735    250467        -1             0            -1   \n",
       "2        -1  1479563953    305197        -1             1            -1   \n",
       "3         7  1480152098    900502        -1             0            -1   \n",
       "4         7  1478368974    542335        -1             0            -1   \n",
       "\n",
       "   platform_name  platform_family  media_duration  listen_type  \\\n",
       "0              1                0             223            0   \n",
       "1              2                1             171            0   \n",
       "2              2                1             149            1   \n",
       "3              0                0             240            0   \n",
       "4              0                0             150            0   \n",
       "\n",
       "         ...          usercontypecluster_5  usercontypecluster_6  \\\n",
       "0        ...                             1                     0   \n",
       "1        ...                             0                     0   \n",
       "2        ...                             0                     0   \n",
       "3        ...                             0                     0   \n",
       "4        ...                             0                     0   \n",
       "\n",
       "   usercontypecluster_7  usercontypecluster_8  usercontypecluster_9  \\\n",
       "0                     0                     0                     0   \n",
       "1                     1                     0                     0   \n",
       "2                     0                     0                     0   \n",
       "3                     0                     0                     0   \n",
       "4                     0                     0                     0   \n",
       "\n",
       "   useruagecluster_0  useruagecluster_1  useruagecluster_2  useruagecluster_3  \\\n",
       "0                  0                  0                  0                  1   \n",
       "1                  1                  0                  0                  0   \n",
       "2                  0                  0                  0                  1   \n",
       "3                  1                  0                  0                  0   \n",
       "4                  0                  1                  0                  0   \n",
       "\n",
       "   useruagecluster_4  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  \n",
       "\n",
       "[5 rows x 683 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.concat([data,dummie1,dummie2,dummie3,dummie4,dummie5,dummie6,dummie7,dummie8,dummie9,dummie10,dummie11,dummie12,dummie13,dummie14,dummie15,dummie16,dummie17,dummie18,dummie19],axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns.get_loc(\"context_type_-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7578752, 648)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = data.iloc[:,35:].as_matrix()# assign feature dataframe to predictors removing the target column\n",
    "target1 = to_categorical(target)# assign target dataframe to y\n",
    "n_cols = predictors.shape[1]\n",
    "predictors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7558834"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictors)-len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "params = {\"objective\": \"binary:logistic\",\"eval_metric\": \"auc\" ,\"booster\": \"gbtree\",\n",
    "          \"eta\": 0.1, \"colsample_bytree\": 0.6, \"min_child_weight\": 0.7,\n",
    "          \"tree_method\": \"exact\", \"seed\": \"1992\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(predictors[0:6000000], target[0:6000000])\n",
    "dvalid = xgb.DMatrix(predictors[6000000:7558834], target[6000000:])\n",
    "dtest = xgb.DMatrix(predictors[7558834:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.718485\n",
      "[20]\ttrain-auc:0.775887\n",
      "[40]\ttrain-auc:0.77915\n",
      "[60]\ttrain-auc:0.782616\n",
      "[80]\ttrain-auc:0.785101\n",
      "[100]\ttrain-auc:0.786802\n",
      "[120]\ttrain-auc:0.788068\n",
      "[140]\ttrain-auc:0.789286\n",
      "[160]\ttrain-auc:0.790227\n",
      "[180]\ttrain-auc:0.791197\n",
      "[200]\ttrain-auc:0.791905\n",
      "[220]\ttrain-auc:0.792559\n",
      "[240]\ttrain-auc:0.793243\n",
      "[260]\ttrain-auc:0.794022\n",
      "[280]\ttrain-auc:0.794589\n"
     ]
    }
   ],
   "source": [
    "nrounds = 300\n",
    "watchlist = [(dtrain, 'train')]\n",
    "bst = xgb.train(params, dtrain, num_boost_round=nrounds, evals=watchlist, verbose_eval=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79157261289555536"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=bst.predict(dvalid)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(target[6000000:], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_preds = bst.predict(dtest)\n",
    "submit = pd.DataFrame({'sample_id': test['sample_id'], 'is_listened': test_preds})\n",
    "submit.to_csv(\"2605/m4_xgb_50_300.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_preds = bst.predict(dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame(train_preds, columns=['pred'])\n",
    "sub1 = pd.DataFrame(pred, columns=['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7558834"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub=pd.concat([sub,sub1],axis=0)\n",
    "len(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub.to_csv(\"train_pred/m4_xgb_50_300_2805.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "early_stopping_monitor = EarlyStopping(patience = 2)\n",
    "\n",
    "# Model\n",
    "model = Sequential()\n",
    "model.add(Dense(96 , activation = 'relu' , input_shape = (n_cols,), kernel_initializer='random_normal',bias_initializer='zeros'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(96 , activation = 'relu', kernel_initializer='random_normal',bias_initializer='zeros'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(14 , activation = 'relu', kernel_initializer='random_normal',bias_initializer='zeros'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(2 , activation = 'softmax'))\n",
    "\n",
    "model.compile(optimizer = 'adadelta' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6000000 samples, validate on 1558834 samples\n",
      "Epoch 1/1\n",
      "6000000/6000000 [==============================] - 661s - loss: 0.5163 - acc: 0.7506 - val_loss: 0.5083 - val_acc: 0.7540\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f18521cdb90>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(predictors[:6000000] , target1[0:6000000] , validation_data = [predictors[6000000:7558834],target1[6000000:]] , epochs = 1 , callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77994142292314395"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_preds = model.predict_proba(predictors[6000000:7558834], verbose=0)\n",
    "valid_preds = valid_preds[:, 1]\n",
    "roc = metrics.roc_auc_score(target1[6000000:,1], valid_preds)\n",
    "roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.84799325,  0.5139755 ,  0.70433617, ...,  0.77603471,\n",
       "        0.71547002,  0.8107174 ], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict_proba(predictors[7558834:], verbose=0)[:, 1]\n",
    "submission = pd.DataFrame(preds, columns=['is_listened'])\n",
    "submission.to_csv('2605/m4_wd_2e_3l_2805_3.csv')\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7558834, 1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_preds = model.predict_proba(predictors[:7558834], verbose=0)[:,1]\n",
    "sub = pd.DataFrame(train_preds, columns=['is_listened'])\n",
    "sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub.to_csv('train_pred/m4_wd_2e_3l_2805_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"models/m4_wd_2e_3l_2805_3.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"models/m4_wd_2e_3l_2805_3.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
