{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import date\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier,ExtraTreesClassifier,AdaBoostClassifier\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv('train.csv')\n",
    "test=pd.read_csv(\"test.csv\")\n",
    "datadiff=pd.read_csv(\"extradata.csv\")\n",
    "testdiff=pd.read_csv(\"extratest.csv\")\n",
    "data=pd.concat([data,datadiff.iloc[:,1:3]],axis=1)\n",
    "test=pd.concat([test,testdiff.iloc[:,1:3]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df43 = pd.DataFrame(data, columns = ['genre_id', 'is_listened'])\n",
    "df45 = pd.DataFrame(data, columns = ['media_id', 'is_listened'])\n",
    "df46=  pd.DataFrame(data, columns = ['album_id', 'is_listened'])\n",
    "df47=  pd.DataFrame(data, columns = ['artist_id', 'is_listened'])\n",
    "df51=  pd.DataFrame(data, columns = ['user_id', 'is_listened'])\n",
    "df53=  pd.DataFrame(data, columns = ['release_date', 'is_listened'])\n",
    "df55=  pd.DataFrame(data, columns = ['time1', 'is_listened'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TO create fractional features. First groupby ids and then calculate mean of is listened for every level of id\n",
    "#and then map it on data using dictionary creation\n",
    "count1=df43.groupby(['genre_id'],as_index=False).agg({'is_listened':'mean'})\n",
    "df44=pd.Series(count1.is_listened.values,index=count1.genre_id).to_dict()\n",
    "data[\"B\"] = data[\"genre_id\"].map(df44)\n",
    "test[\"B\"] = test[\"genre_id\"].map(df44)\n",
    "\n",
    "\n",
    "count2=df45.groupby(['media_id'],as_index=False).agg({'is_listened':'mean'})\n",
    "df48=pd.Series(count2.is_listened.values,index=count2.media_id).to_dict()\n",
    "data[\"C\"] = data[\"media_id\"].map(df48)\n",
    "test[\"C\"] = test[\"media_id\"].map(df48)\n",
    "\n",
    "count3=df46.groupby(['album_id'],as_index=False).agg({'is_listened':'mean'})\n",
    "df49=pd.Series(count3.is_listened.values,index=count3.album_id).to_dict()\n",
    "data[\"D\"] = data[\"album_id\"].map(df49)\n",
    "test[\"D\"] = test[\"album_id\"].map(df49)\n",
    "\n",
    "count4=df47.groupby(['artist_id'],as_index=False).agg({'is_listened':'mean'})\n",
    "df50=pd.Series(count4.is_listened.values,index=count4.artist_id).to_dict()\n",
    "data[\"E\"] = data[\"artist_id\"].map(df50)\n",
    "test[\"E\"] = test[\"artist_id\"].map(df50)\n",
    "\n",
    "count5=df51.groupby(['user_id'],as_index=False).agg({'is_listened':'mean'})\n",
    "df52=pd.Series(count5.is_listened.values,index=count5.user_id).to_dict()\n",
    "data[\"F\"] = data[\"user_id\"].map(df52)\n",
    "test[\"F\"] = test[\"user_id\"].map(df52)\n",
    "\n",
    "count6=df53.groupby(['release_date'],as_index=False).agg({'is_listened':'mean'})\n",
    "df54=pd.Series(count6.is_listened.values,index=count6.release_date).to_dict()\n",
    "data[\"G\"] = data[\"release_date\"].map(df54)\n",
    "test[\"G\"] = test[\"release_date\"].map(df54)\n",
    "\n",
    "count7=df55.groupby(['time1'],as_index=False).agg({'is_listened':'mean'})\n",
    "df56=pd.Series(count7.is_listened.values,index=count7.time1).to_dict()\n",
    "data[\"H\"] = data[\"time1\"].map(df56)\n",
    "test[\"H\"] = test[\"time1\"].map(df56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/pandas/core/indexing.py:179: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "#pivot table for clustering of similar users. Till now only used genre id for cluster\n",
    "matrix = data.pivot_table(index=['user_id'], columns=['genre_id'], values='is_listened')\n",
    "from sklearn.cluster import KMeans\n",
    "cluster = KMeans(n_clusters=70)\n",
    "matrix=matrix.fillna(0)\n",
    "x_cols = matrix.columns[1:]\n",
    "#the below line is server specific and is used to predict cluster of users and then we have mapped users on clusters\n",
    "matrix['cluster'] = cluster.fit_predict(matrix[matrix.columns[1:]])\n",
    "#matrix1=pd.concat([matrix.iloc[:,0],matrix['cluster']],axis=1)\n",
    "matrix1=pd.concat([pd.DataFrame(matrix.index.values),matrix['cluster']],axis=1)\n",
    "matrix1.columns=['user_id','cluster']\n",
    "mat2=pd.Series(matrix1.cluster.values,index=matrix1.user_id.values).to_dict()\n",
    "data[\"usergencluster\"] = data[\"user_id\"].map(mat2)\n",
    "test[\"usergencluster\"]=test[\"user_id\"].map(mat2)\n",
    "\n",
    "data['album_id_1']=data['album_id']\n",
    "test['album_id_1']=test['album_id']\n",
    "mmo3=pd.DataFrame(data['album_id_1'].value_counts())\n",
    "mmo3=pd.concat([pd.DataFrame(mmo3.index.values),pd.DataFrame(mmo3.album_id_1.values)],axis=1)\n",
    "mmo31=list(mmo3.iloc[1500:,0])\n",
    "data['album_id_1'].loc[data['album_id_1'].isin(mmo31)]=-1\n",
    "matrix = data.pivot_table(index=['user_id'], columns=['album_id_1'], values='is_listened')\n",
    "cluster = KMeans(n_clusters=100)\n",
    "matrix=matrix.fillna(0)\n",
    "#the below line is server specific and is used to predict cluster of users and then we have mapped users on clusters\n",
    "matrix['cluster'] = cluster.fit_predict(matrix[matrix.columns[1:]])\n",
    "#matrix1=pd.concat([matrix.iloc[:,0],matrix['cluster']],axis=1)\n",
    "matrix1=pd.concat([pd.DataFrame(matrix.index.values),matrix['cluster']],axis=1)\n",
    "matrix1.columns=['user_id','cluster']\n",
    "mat2=pd.Series(matrix1.cluster.values,index=matrix1.user_id.values).to_dict()\n",
    "data[\"useralbcluster\"] = data[\"user_id\"].map(mat2)\n",
    "test[\"useralbcluster\"]=test[\"user_id\"].map(mat2)\n",
    "\n",
    "data['media_id_1']=data['media_id']\n",
    "test['media_id_1']=test['media_id']\n",
    "mmo3=pd.DataFrame(data['media_id_1'].value_counts())\n",
    "mmo3=pd.concat([pd.DataFrame(mmo3.index.values),pd.DataFrame(mmo3.media_id_1.values)],axis=1)\n",
    "mmo31=list(mmo3.iloc[3000:,0])\n",
    "data['media_id_1'].loc[data['media_id_1'].isin(mmo31)]=-1\n",
    "matrix = data.pivot_table(index=['user_id'], columns=['media_id_1'], values='is_listened')\n",
    "cluster = KMeans(n_clusters=100)\n",
    "matrix=matrix.fillna(0)\n",
    "#the below line is server specific and is used to predict cluster of users and then we have mapped users on clusters\n",
    "matrix['cluster'] = cluster.fit_predict(matrix[matrix.columns[1:]])\n",
    "#matrix1=pd.concat([matrix.iloc[:,0],matrix['cluster']],axis=1)\n",
    "matrix1=pd.concat([pd.DataFrame(matrix.index.values),matrix['cluster']],axis=1)\n",
    "matrix1.columns=['user_id','cluster']\n",
    "mat2=pd.Series(matrix1.cluster.values,index=matrix1.user_id.values).to_dict()\n",
    "data[\"usermedcluster\"] = data[\"user_id\"].map(mat2)\n",
    "test[\"usermedcluster\"]=test[\"user_id\"].map(mat2)\n",
    "\n",
    "data['artist_id_1']=data['artist_id']\n",
    "test['artist_id_1']=test['artist_id']\n",
    "mmo3=pd.DataFrame(data['artist_id_1'].value_counts())\n",
    "mmo3=pd.concat([pd.DataFrame(mmo3.index.values),pd.DataFrame(mmo3.artist_id_1.values)],axis=1)\n",
    "mmo31=list(mmo3.iloc[1700:,0])\n",
    "data['artist_id_1'].loc[data['artist_id_1'].isin(mmo31)]=-1\n",
    "matrix = data.pivot_table(index=['user_id'], columns=['artist_id_1'], values='is_listened')\n",
    "cluster = KMeans(n_clusters=80)\n",
    "matrix=matrix.fillna(0)\n",
    "#the below line is server specific and is used to predict cluster of users and then we have mapped users on clusters\n",
    "matrix['cluster'] = cluster.fit_predict(matrix[matrix.columns[1:]])\n",
    "#matrix1=pd.concat([matrix.iloc[:,0],matrix['cluster']],axis=1)\n",
    "matrix1=pd.concat([pd.DataFrame(matrix.index.values),matrix['cluster']],axis=1)\n",
    "matrix1.columns=['user_id','cluster']\n",
    "mat2=pd.Series(matrix1.cluster.values,index=matrix1.user_id.values).to_dict()\n",
    "data[\"userartcluster\"] = data[\"user_id\"].map(mat2)\n",
    "test[\"userartcluster\"]=test[\"user_id\"].map(mat2)\n",
    "\n",
    "matrix=0\n",
    "data['release_date_1']=data['release_date']\n",
    "test['release_date_1']=test['release_date']\n",
    "mmo3=pd.DataFrame(data['release_date_1'].value_counts())\n",
    "mmo3=pd.concat([pd.DataFrame(mmo3.index.values),pd.DataFrame(mmo3.release_date_1.values)],axis=1)\n",
    "mmo31=list(mmo3.iloc[1000:,0])\n",
    "data['release_date_1'].loc[data['release_date_1'].isin(mmo31)]=-1\n",
    "matrix = data.pivot_table(index=['user_id'], columns=['release_date_1'], values='is_listened')\n",
    "cluster = KMeans(n_clusters=10)\n",
    "matrix=matrix.fillna(0)\n",
    "#the below line is server specific and is used to predict cluster of users and then we have mapped users on clusters\n",
    "matrix['cluster'] = cluster.fit_predict(matrix[matrix.columns[1:]])\n",
    "#matrix1=pd.concat([matrix.iloc[:,0],matrix['cluster']],axis=1)\n",
    "matrix1=pd.concat([pd.DataFrame(matrix.index.values),matrix['cluster']],axis=1)\n",
    "matrix1.columns=['user_id','cluster']\n",
    "mat2=pd.Series(matrix1.cluster.values,index=matrix1.user_id.values).to_dict()\n",
    "data[\"userdatecluster\"] = data[\"user_id\"].map(mat2)\n",
    "test[\"userdatecluster\"]=test[\"user_id\"].map(mat2)\n",
    "\n",
    "matrix=0\n",
    "data['time1_1']=data['time1']\n",
    "test['time1_1']=test['time1']\n",
    "mmo3=pd.DataFrame(data['time1_1'].value_counts())\n",
    "mmo3=pd.concat([pd.DataFrame(mmo3.index.values),pd.DataFrame(mmo3.time1_1.values)],axis=1)\n",
    "mmo31=list(mmo3.iloc[:,0])\n",
    "#data['time1_1'].loc[data['time1_1'].isin(mmo31)]=-1\n",
    "matrix = data.pivot_table(index=['user_id'], columns=['time1_1'], values='is_listened')\n",
    "cluster = KMeans(n_clusters=4)\n",
    "matrix=matrix.fillna(0)\n",
    "#the below line is server specific and is used to predict cluster of users and then we have mapped users on clusters\n",
    "matrix['cluster'] = cluster.fit_predict(matrix[matrix.columns[1:]])\n",
    "#matrix1=pd.concat([matrix.iloc[:,0],matrix['cluster']],axis=1)\n",
    "matrix1=pd.concat([pd.DataFrame(matrix.index.values),matrix['cluster']],axis=1)\n",
    "matrix1.columns=['user_id','cluster']\n",
    "mat2=pd.Series(matrix1.cluster.values,index=matrix1.user_id.values).to_dict()\n",
    "data[\"usertimecluster\"] = data[\"user_id\"].map(mat2)\n",
    "test[\"usertimecluster\"]=test[\"user_id\"].map(mat2)\n",
    "\n",
    "matrix=0\n",
    "data['user_age1']=data['user_age']\n",
    "test['user_age1']=test['user_age']\n",
    "mmo3=pd.DataFrame(data['user_age1'].value_counts())\n",
    "mmo3=pd.concat([pd.DataFrame(mmo3.index.values),pd.DataFrame(mmo3.user_age1.values)],axis=1)\n",
    "mmo31=list(mmo3.iloc[1000:,0])\n",
    "data['user_age1'].loc[data['user_age1'].isin(mmo31)]=-1\n",
    "matrix = data.pivot_table(index=['user_id'], columns=['user_age1'], values='is_listened')\n",
    "cluster = KMeans(n_clusters=4)\n",
    "matrix=matrix.fillna(0)\n",
    "#the below line is server specific and is used to predict cluster of users and then we have mapped users on clusters\n",
    "matrix['cluster'] = cluster.fit_predict(matrix[matrix.columns[1:]])\n",
    "#matrix1=pd.concat([matrix.iloc[:,0],matrix['cluster']],axis=1)\n",
    "matrix1=pd.concat([pd.DataFrame(matrix.index.values),matrix['cluster']],axis=1)\n",
    "matrix1.columns=['user_id','cluster']\n",
    "mat2=pd.Series(matrix1.cluster.values,index=matrix1.user_id.values).to_dict()\n",
    "data[\"useragecluster\"] = data[\"user_id\"].map(mat2)\n",
    "test[\"useragecluster\"]=test[\"user_id\"].map(mat2)\n",
    "\n",
    "matrix=0\n",
    "data['context_type1']=data['context_type']\n",
    "test['context_type1']=test['context_type']\n",
    "mmo3=pd.DataFrame(data['context_type1'].value_counts())\n",
    "mmo3=pd.concat([pd.DataFrame(mmo3.index.values),pd.DataFrame(mmo3.context_type1.values)],axis=1)\n",
    "mmo31=list(mmo3.iloc[1000:,0])\n",
    "data['context_type1'].loc[data['context_type1'].isin(mmo31)]=-1\n",
    "matrix = data.pivot_table(index=['user_id'], columns=['context_type1'], values='is_listened')\n",
    "cluster = KMeans(n_clusters=10)\n",
    "matrix=matrix.fillna(0)\n",
    "#the below line is server specific and is used to predict cluster of users and then we have mapped users on clusters\n",
    "matrix['cluster'] = cluster.fit_predict(matrix[matrix.columns[1:]])\n",
    "#matrix1=pd.concat([matrix.iloc[:,0],matrix['cluster']],axis=1)\n",
    "matrix1=pd.concat([pd.DataFrame(matrix.index.values),matrix['cluster']],axis=1)\n",
    "matrix1.columns=['user_id','cluster']\n",
    "mat2=pd.Series(matrix1.cluster.values,index=matrix1.user_id.values).to_dict()\n",
    "data[\"usercontcluster\"] = data[\"user_id\"].map(mat2)\n",
    "test[\"usercontcluster\"]=test[\"user_id\"].map(mat2)\n",
    "\n",
    "matrix=0\n",
    "data['platform_name1']=data['platform_name']\n",
    "test['platform_name1']=test['platform_name']\n",
    "mmo3=pd.DataFrame(data['platform_name1'].value_counts())\n",
    "mmo3=pd.concat([pd.DataFrame(mmo3.index.values),pd.DataFrame(mmo3.platform_name1.values)],axis=1)\n",
    "mmo31=list(mmo3.iloc[1000:,0])\n",
    "data['platform_name1'].loc[data['platform_name1'].isin(mmo31)]=-1\n",
    "matrix = data.pivot_table(index=['user_id'], columns=['platform_name1'], values='is_listened')\n",
    "cluster = KMeans(n_clusters=10)\n",
    "matrix=matrix.fillna(0)\n",
    "#the below line is server specific and is used to predict cluster of users and then we have mapped users on clusters\n",
    "matrix['cluster'] = cluster.fit_predict(matrix[matrix.columns[1:]])\n",
    "#matrix1=pd.concat([matrix.iloc[:,0],matrix['cluster']],axis=1)\n",
    "matrix1=pd.concat([pd.DataFrame(matrix.index.values),matrix['cluster']],axis=1)\n",
    "matrix1.columns=['user_id','cluster']\n",
    "mat2=pd.Series(matrix1.cluster.values,index=matrix1.user_id.values).to_dict()\n",
    "data[\"userplatcluster\"] = data[\"user_id\"].map(mat2)\n",
    "test[\"userplatcluster\"]=test[\"user_id\"].map(mat2)\n",
    "\n",
    "matrix=0\n",
    "#data['platform_name1']=data['platform_name']\n",
    "#test['platform_name1']=test['platform_name']\n",
    "#mmo3=pd.DataFrame(data['platform_name1'].value_counts())\n",
    "#mmo3=pd.concat([pd.DataFrame(mmo3.index.values),pd.DataFrame(mmo3.platform_name1.values)],axis=1)\n",
    "#mmo31=list(mmo3.iloc[1000:,0])\n",
    "#data['platform_name1'].loc[data['platform_name1'].isin(mmo31)]=-1\n",
    "matrix = data.pivot_table(index=['user_id'], columns=['user_gender'], values='is_listened')\n",
    "cluster = KMeans(n_clusters=6)\n",
    "matrix=matrix.fillna(0)\n",
    "#the below line is server specific and is used to predict cluster of users and then we have mapped users on clusters\n",
    "matrix['cluster'] = cluster.fit_predict(matrix[matrix.columns[1:]])\n",
    "#matrix1=pd.concat([matrix.iloc[:,0],matrix['cluster']],axis=1)\n",
    "matrix1=pd.concat([pd.DataFrame(matrix.index.values),matrix['cluster']],axis=1)\n",
    "matrix1.columns=['user_id','cluster']\n",
    "mat2=pd.Series(matrix1.cluster.values,index=matrix1.user_id.values).to_dict()\n",
    "data[\"usergendcluster\"] = data[\"user_id\"].map(mat2)\n",
    "test[\"usergendcluster\"]=test[\"user_id\"].map(mat2)\n",
    "\n",
    "matrix=0\n",
    "matrix = data.pivot_table(index=['genre_id'], columns=['user_age'], values='is_listened')\n",
    "cluster = KMeans(n_clusters=5)\n",
    "matrix=matrix.fillna(0)\n",
    "#the below line is server specific and is used to predict cluster of users and then we have mapped users on clusters\n",
    "matrix['cluster'] = cluster.fit_predict(matrix[matrix.columns[0:]])\n",
    "#matrix1=pd.concat([matrix.iloc[:,0],matrix['cluster']],axis=1)\n",
    "opp=pd.DataFrame(matrix.index.values)\n",
    "opp.reset_index(drop=True)\n",
    "matrix1=pd.concat([opp,(pd.DataFrame(matrix['cluster'])).reset_index(drop=True)],axis=1,ignore_index=True).reset_index(drop=True)\n",
    "matrix1.columns=['genre_id','cluster']\n",
    "mat2=pd.Series(matrix1.cluster.values,index=matrix1.genre_id.values).to_dict()\n",
    "data[\"genreagecluster\"] = data[\"genre_id\"].map(mat2)\n",
    "test[\"genreagecluster\"]=test[\"genre_id\"].map(mat2)\n",
    "\n",
    "matrix = data.pivot_table(index=['genre_id'], columns=['context_type1'], values='is_listened')\n",
    "cluster = KMeans(n_clusters=10)\n",
    "matrix=matrix.fillna(0)\n",
    "#the below line is server specific and is used to predict cluster of users and then we have mapped users on clusters\n",
    "matrix['cluster'] = cluster.fit_predict(matrix[matrix.columns[0:]])\n",
    "#matrix1=pd.concat([matrix.iloc[:,0],matrix['cluster']],axis=1)\n",
    "opp=pd.DataFrame(matrix.index.values)\n",
    "opp.reset_index(drop=True)\n",
    "matrix1=pd.concat([opp,(pd.DataFrame(matrix['cluster'])).reset_index(drop=True)],axis=1,ignore_index=True).reset_index(drop=True)\n",
    "matrix1.columns=['genre_id','cluster']\n",
    "mat2=pd.Series(matrix1.cluster.values,index=matrix1.genre_id.values).to_dict()\n",
    "data[\"genrecontcluster\"] = data[\"genre_id\"].map(mat2)\n",
    "test[\"genrecontcluster\"]=test[\"genre_id\"].map(mat2)\n",
    "\n",
    "matrix=0\n",
    "data['listen_type1']=data['listen_type']\n",
    "test['listen_type1']=test['listen_type']\n",
    "\n",
    "matrix = data.pivot_table(index=['genre_id'], columns=['listen_type1'], values='is_listened')\n",
    "cluster = KMeans(n_clusters=5)\n",
    "matrix=matrix.fillna(0)\n",
    "#the below line is server specific and is used to predict cluster of users and then we have mapped users on clusters\n",
    "matrix['cluster'] = cluster.fit_predict(matrix[matrix.columns[0:]])\n",
    "#matrix1=pd.concat([matrix.iloc[:,0],matrix['cluster']],axis=1)\n",
    "opp=pd.DataFrame(matrix.index.values)\n",
    "opp.reset_index(drop=True)\n",
    "matrix1=pd.concat([opp,(pd.DataFrame(matrix['cluster'])).reset_index(drop=True)],axis=1,ignore_index=True).reset_index(drop=True)\n",
    "matrix1.columns=['genre_id','cluster']\n",
    "mat2=pd.Series(matrix1.cluster.values,index=matrix1.genre_id.values).to_dict()\n",
    "data[\"genrelistcluster\"] = data[\"genre_id\"].map(mat2)\n",
    "test[\"genrelistcluster\"]=test[\"genre_id\"].map(mat2)\n",
    "\n",
    "matrix = data.pivot_table(index=['genre_id'], columns=['user_gender'], values='is_listened')\n",
    "cluster = KMeans(n_clusters=5)\n",
    "matrix=matrix.fillna(0)\n",
    "#the below line is server specific and is used to predict cluster of users and then we have mapped users on clusters\n",
    "matrix['cluster'] = cluster.fit_predict(matrix[matrix.columns[0:]])\n",
    "#matrix1=pd.concat([matrix.iloc[:,0],matrix['cluster']],axis=1)\n",
    "opp=pd.DataFrame(matrix.index.values)\n",
    "opp.reset_index(drop=True)\n",
    "matrix1=pd.concat([opp,(pd.DataFrame(matrix['cluster'])).reset_index(drop=True)],axis=1,ignore_index=True).reset_index(drop=True)\n",
    "matrix1.columns=['genre_id','cluster']\n",
    "mat2=pd.Series(matrix1.cluster.values,index=matrix1.genre_id.values).to_dict()\n",
    "data[\"genregendcluster\"] = data[\"genre_id\"].map(mat2)\n",
    "test[\"genregendcluster\"]=test[\"genre_id\"].map(mat2)\n",
    "\n",
    "matrix = data.pivot_table(index=['genre_id'], columns=['user_age'], values='is_listened')\n",
    "cluster = KMeans(n_clusters=4)\n",
    "matrix=matrix.fillna(0)\n",
    "#the below line is server specific and is used to predict cluster of users and then we have mapped users on clusters\n",
    "matrix['cluster'] = cluster.fit_predict(matrix[matrix.columns[0:]])\n",
    "#matrix1=pd.concat([matrix.iloc[:,0],matrix['cluster']],axis=1)\n",
    "opp=pd.DataFrame(matrix.index.values)\n",
    "opp.reset_index(drop=True)\n",
    "matrix1=pd.concat([opp,(pd.DataFrame(matrix['cluster'])).reset_index(drop=True)],axis=1,ignore_index=True).reset_index(drop=True)\n",
    "matrix1.columns=['genre_id','cluster']\n",
    "mat2=pd.Series(matrix1.cluster.values,index=matrix1.genre_id.values).to_dict()\n",
    "data[\"genreagecluster\"] = data[\"genre_id\"].map(mat2)\n",
    "test[\"genreagedcluster\"]=test[\"genre_id\"].map(mat2)\n",
    "\n",
    "\n",
    "#mmo3=pd.DataFrame(data['platform_name1'].value_counts())\n",
    "#mmo3=pd.concat([pd.DataFrame(mmo3.index.values),pd.DataFrame(mmo3.platform_name1.values)],axis=1)\n",
    "#mmo31=list(mmo3.iloc[1000:,0])\n",
    "#data['platform_name1'].loc[data['platform_name1'].isin(mmo31)]=-1\n",
    "matrix = data.pivot_table(index=['user_id'], columns=['listen_type1'], values='is_listened')\n",
    "cluster = KMeans(n_clusters=10)\n",
    "matrix=matrix.fillna(0)\n",
    "#the below line is server specific and is used to predict cluster of users and then we have mapped users on clusters\n",
    "matrix['cluster'] = cluster.fit_predict(matrix[matrix.columns[1:]])\n",
    "#matrix1=pd.concat([matrix.iloc[:,0],matrix['cluster']],axis=1)\n",
    "matrix1=pd.concat([pd.DataFrame(matrix.index.values),matrix['cluster']],axis=1)\n",
    "matrix1.columns=['user_id','cluster']\n",
    "mat2=pd.Series(matrix1.cluster.values,index=matrix1.user_id.values).to_dict()\n",
    "data[\"userlisttypecluster\"] = data[\"user_id\"].map(mat2)\n",
    "test[\"userlisttypecluster\"]=test[\"user_id\"].map(mat2)\n",
    "\n",
    "matrix = data.pivot_table(index=['user_id'], columns=['platform_family'], values='is_listened')\n",
    "cluster = KMeans(n_clusters=10)\n",
    "matrix=matrix.fillna(0)\n",
    "x_cols = matrix.columns[1:]\n",
    "matrix['cluster'] = cluster.fit_predict(matrix[matrix.columns[1:]])\n",
    "matrix1=pd.concat([pd.DataFrame(matrix.index.values),matrix['cluster']],axis=1)\n",
    "matrix1.columns=['user_id','cluster']\n",
    "mat2=pd.Series(matrix1.cluster.values,index=matrix1.user_id.values).to_dict()\n",
    "data[\"userplafamcluster\"] = data[\"user_id\"].map(mat2)\n",
    "test[\"userplafamcluster\"]=test[\"user_id\"].map(mat2)\n",
    "\n",
    "matrix = data.pivot_table(index=['artist_id'], columns=['user_gender'], values='is_listened')\n",
    "cluster = KMeans(n_clusters=6)\n",
    "matrix=matrix.fillna(0)\n",
    "#the below line is server specific and is used to predict cluster of users and then we have mapped users on clusters\n",
    "matrix['cluster'] = cluster.fit_predict(matrix[matrix.columns[1:]])\n",
    "#matrix1=pd.concat([matrix.iloc[:,0],matrix['cluster']],axis=1)\n",
    "opp=pd.DataFrame(matrix.index.values)\n",
    "opp.reset_index(drop=True)\n",
    "matrix1=pd.concat([opp,(pd.DataFrame(matrix['cluster'])).reset_index(drop=True)],axis=1,ignore_index=True).reset_index(drop=True)\n",
    "matrix1.columns=['artist_id','cluster']\n",
    "mat2=pd.Series(matrix1.cluster.values,index=matrix1.artist_id.values).to_dict()\n",
    "data[\"artistgendcluster\"] = data[\"artist_id\"].map(mat2)\n",
    "test[\"artistgendcluster\"]=test[\"artist_id\"].map(mat2)\n",
    "\n",
    "matrix = data.pivot_table(index=['artist_id'], columns=['listen_type1'], values='is_listened')\n",
    "cluster = KMeans(n_clusters=10)\n",
    "matrix=matrix.fillna(0)\n",
    "#the below line is server specific and is used to predict cluster of users and then we have mapped users on clusters\n",
    "matrix['cluster'] = cluster.fit_predict(matrix[matrix.columns[1:]])\n",
    "#matrix1=pd.concat([matrix.iloc[:,0],matrix['cluster']],axis=1)\n",
    "opp=pd.DataFrame(matrix.index.values)\n",
    "opp.reset_index(drop=True)\n",
    "matrix1=pd.concat([opp,(pd.DataFrame(matrix['cluster'])).reset_index(drop=True)],axis=1,ignore_index=True).reset_index(drop=True)\n",
    "matrix1.columns=['artist_id','cluster']\n",
    "mat2=pd.Series(matrix1.cluster.values,index=matrix1.artist_id.values).to_dict()\n",
    "data[\"artistlisttypecluster\"] = data[\"artist_id\"].map(mat2)\n",
    "test[\"artistlisttypecluster\"]=test[\"artist_id\"].map(mat2)\n",
    "\n",
    "matrix = data.pivot_table(index=['artist_id'], columns=['listen_type1'], values='is_listened')\n",
    "cluster = KMeans(n_clusters=10)\n",
    "matrix=matrix.fillna(0)\n",
    "#the below line is server specific and is used to predict cluster of users and then we have mapped users on clusters\n",
    "matrix['cluster'] = cluster.fit_predict(matrix[matrix.columns[1:]])\n",
    "#matrix1=pd.concat([matrix.iloc[:,0],matrix['cluster']],axis=1)\n",
    "opp=pd.DataFrame(matrix.index.values)\n",
    "opp.reset_index(drop=True)\n",
    "matrix1=pd.concat([opp,(pd.DataFrame(matrix['cluster'])).reset_index(drop=True)],axis=1,ignore_index=True).reset_index(drop=True)\n",
    "matrix1.columns=['artist_id','cluster']\n",
    "mat2=pd.Series(matrix1.cluster.values,index=matrix1.artist_id.values).to_dict()\n",
    "data[\"artistlisttypecluster\"] = data[\"artist_id\"].map(mat2)\n",
    "test[\"artistlisttypecluster\"]=test[\"artist_id\"].map(mat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from six.moves import cPickle as pickle\n",
    "#data.to_pickle(\"data3005.pickle\")\n",
    "#test.to_pickle(\"test3005.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mmo3=pd.DataFrame(data['media_id'].value_counts())\n",
    "mmo98=pd.DataFrame(test['media_id'].value_counts())\n",
    "unmatched = set(list(mmo98.index.values))-set(list(mmo3.index.values))\n",
    "test['media_id'].loc[test['media_id'].isin(list(unmatched)[65:])]=-2\n",
    "mmo3=pd.concat([pd.DataFrame(mmo3.index.values),pd.DataFrame(mmo3.media_id.values)],axis=1)\n",
    "df=pd.Series(mmo3.iloc[:,1].values,index=mmo3.iloc[:,0].values).to_dict()\n",
    "data[\"media_id_freq\"] = data[\"media_id\"].map(df)\n",
    "test[\"media_id_freq\"] = test[\"media_id\"].map(df)\n",
    "mmo31=list(mmo3.iloc[100:,0])\n",
    "data['media_id'].loc[data['media_id'].isin(mmo31)]=-1\n",
    "test['media_id'].loc[test['media_id'].isin(mmo31)]=-1\n",
    "\n",
    "\n",
    "mmo3=pd.DataFrame(data['album_id'].value_counts())\n",
    "mmo98=pd.DataFrame(test['album_id'].value_counts())\n",
    "unmatched = set(list(mmo98.index.values))-set(list(mmo3.index.values))\n",
    "test['album_id'].loc[test['album_id'].isin(list(unmatched)[65:])]=-2\n",
    "mmo3=pd.concat([pd.DataFrame(mmo3.index.values),pd.DataFrame(mmo3.album_id.values)],axis=1)\n",
    "df=pd.Series(mmo3.iloc[:,1].values,index=mmo3.iloc[:,0].values).to_dict()\n",
    "data[\"album_id_freq\"] = data[\"album_id\"].map(df)\n",
    "test[\"album_id_freq\"] = test[\"album_id\"].map(df)\n",
    "mmo31=list(mmo3.iloc[100:,0])\n",
    "data['album_id'].loc[data['album_id'].isin(mmo31)]=-1\n",
    "test['album_id'].loc[test['album_id'].isin(mmo31)]=-1\n",
    "\n",
    "mmo4=pd.DataFrame(data['artist_id'].value_counts())\n",
    "mmo98=pd.DataFrame(test['artist_id'].value_counts())\n",
    "unmatched = set(list(mmo98.index.values))-set(list(mmo4.index.values))\n",
    "test['artist_id'].loc[test['artist_id'].isin(list(unmatched)[40:])]=-2\n",
    "mmo4=pd.concat([pd.DataFrame(mmo4.index.values),pd.DataFrame(mmo4.artist_id.values)],axis=1)\n",
    "df=pd.Series(mmo4.iloc[:,1].values,index=mmo4.iloc[:,0].values).to_dict()\n",
    "data[\"artist_id_freq\"] = data[\"artist_id\"].map(df)\n",
    "test[\"artist_id_freq\"] = test[\"artist_id\"].map(df)\n",
    "mmo41=list(mmo4.iloc[100:,0])\n",
    "data['artist_id'].loc[data['artist_id'].isin(mmo41)]=-1\n",
    "test['artist_id'].loc[test['artist_id'].isin(mmo41)]=-1\n",
    "\n",
    "      \n",
    "mmo5=pd.DataFrame(data['genre_id'].value_counts())\n",
    "mmo98=pd.DataFrame(test['genre_id'].value_counts())\n",
    "unmatched = set(list(mmo98.index.values))-set(list(mmo5.index.values))\n",
    "test['genre_id'].loc[test['genre_id'].isin(unmatched)]=-2\n",
    "mmo5=pd.concat([pd.DataFrame(mmo5.index.values),pd.DataFrame(mmo5.genre_id.values)],axis=1)\n",
    "df=pd.Series(mmo5.iloc[:,1].values,index=mmo5.iloc[:,0].values).to_dict()\n",
    "data[\"genre_id_freq\"] = data[\"genre_id\"].map(df)\n",
    "test[\"genre_id_freq\"] = test[\"genre_id\"].map(df)\n",
    "mmo51=list(mmo5.iloc[50:,0])\n",
    "data['genre_id'].loc[data['genre_id'].isin(mmo51)]=-1\n",
    "test['genre_id'].loc[test['genre_id'].isin(mmo51)]=-1\n",
    "\n",
    "mmo6=pd.DataFrame(data['context_type'].value_counts())\n",
    "mmo6=pd.concat([pd.DataFrame(mmo6.index.values),pd.DataFrame(mmo6.context_type.values)],axis=1)\n",
    "mmo61=list(mmo6.iloc[25:,0])\n",
    "data['context_type'].loc[data['context_type'].isin(mmo61)]=-1\n",
    "test['context_type'].loc[test['context_type'].isin(mmo61)]=-1\n",
    "\n",
    "\n",
    "mmo7=pd.DataFrame(data['release_date'].value_counts())\n",
    "mmo98=pd.DataFrame(test['release_date'].value_counts())\n",
    "#unmatched = set(list(mmo98.index.values))-set(list(mmo7.index.values))\n",
    "#test['release_date'].loc[test['release_date'].isin(unmatched)]=-1\n",
    "mmo7=pd.concat([pd.DataFrame(mmo7.index.values),pd.DataFrame(mmo7.release_date.values)],axis=1)\n",
    "mmo71=list(mmo7.iloc[25:,0])\n",
    "data['release_date'].loc[data['release_date'].isin(mmo71)]=-1\n",
    "test['release_date'].loc[test['release_date'].isin(mmo71)]=-1\n",
    "matrix=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mmo3=0\n",
    "mmo31=0\n",
    "mmo4=0\n",
    "mmo5=0\n",
    "mmo6=0\n",
    "mmo7=0\n",
    "mmo41=0\n",
    "mmo51=0\n",
    "mmo61=0\n",
    "mmo71=0\n",
    "mmo98=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre_id</th>\n",
       "      <th>ts_listen</th>\n",
       "      <th>media_id</th>\n",
       "      <th>album_id</th>\n",
       "      <th>context_type</th>\n",
       "      <th>release_date</th>\n",
       "      <th>platform_name</th>\n",
       "      <th>platform_family</th>\n",
       "      <th>media_duration</th>\n",
       "      <th>listen_type</th>\n",
       "      <th>...</th>\n",
       "      <th>genregendcluster</th>\n",
       "      <th>genreagedcluster</th>\n",
       "      <th>userlisttypecluster</th>\n",
       "      <th>userplafamcluster</th>\n",
       "      <th>artistgendcluster</th>\n",
       "      <th>artistlisttypecluster</th>\n",
       "      <th>media_id_freq</th>\n",
       "      <th>album_id_freq</th>\n",
       "      <th>artist_id_freq</th>\n",
       "      <th>genre_id_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>1478104371</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>542</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1111.0</td>\n",
       "      <td>79158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2744</td>\n",
       "      <td>1479317140</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>307</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>1363.0</td>\n",
       "      <td>5536.0</td>\n",
       "      <td>84702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2744</td>\n",
       "      <td>1479546361</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>307</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>1363.0</td>\n",
       "      <td>5536.0</td>\n",
       "      <td>84702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2744</td>\n",
       "      <td>1478457729</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>265</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>1363.0</td>\n",
       "      <td>5536.0</td>\n",
       "      <td>84702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2744</td>\n",
       "      <td>1480448560</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>356</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1363.0</td>\n",
       "      <td>5536.0</td>\n",
       "      <td>84702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   genre_id   ts_listen  media_id  album_id  context_type  release_date  \\\n",
       "0        50  1478104371        -1        -1             1            -1   \n",
       "1      2744  1479317140        -1        -1             1            -1   \n",
       "2      2744  1479546361        -1        -1             1            -1   \n",
       "3      2744  1478457729        -1        -1             1            -1   \n",
       "4      2744  1480448560        -1        -1             1            -1   \n",
       "\n",
       "   platform_name  platform_family  media_duration  listen_type      ...        \\\n",
       "0              0                0             542            1      ...         \n",
       "1              0                0             307            1      ...         \n",
       "2              0                0             307            1      ...         \n",
       "3              2                1             265            1      ...         \n",
       "4              2                1             356            1      ...         \n",
       "\n",
       "   genregendcluster  genreagedcluster  userlisttypecluster  userplafamcluster  \\\n",
       "0                 1                 2                    2                  0   \n",
       "1                 1                 2                    0                  0   \n",
       "2                 1                 2                    5                  0   \n",
       "3                 1                 2                    2                  2   \n",
       "4                 1                 2                    6                  1   \n",
       "\n",
       "   artistgendcluster  artistlisttypecluster  media_id_freq  album_id_freq  \\\n",
       "0                3.0                    8.0            6.0           20.0   \n",
       "1                3.0                    8.0          441.0         1363.0   \n",
       "2                3.0                    8.0          441.0         1363.0   \n",
       "3                3.0                    8.0          176.0         1363.0   \n",
       "4                3.0                    8.0           15.0         1363.0   \n",
       "\n",
       "   artist_id_freq  genre_id_freq  \n",
       "0          1111.0          79158  \n",
       "1          5536.0          84702  \n",
       "2          5536.0          84702  \n",
       "3          5536.0          84702  \n",
       "4          5536.0          84702  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target=data['is_listened']\n",
    "del data['is_listened']\n",
    "test2=test.iloc[:,1:] \n",
    "data.head()\n",
    "test2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=pd.concat([data,test2],axis=0)\n",
    "data=data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#MediaDuration\n",
    "data['media_duration'].loc[(data['media_duration']>=500) ]=0\n",
    "#data['media_duration'].loc[(data['media_duration']>=400 )&( data['media_duration']<500) ]=1\n",
    "#data['media_duration'].loc[(data['media_duration']>=300 )&( data['media_duration']<500) ]=2\n",
    "data['media_duration'].loc[(data['media_duration']>=250 )&( data['media_duration']<500) ]=-3\n",
    "data['media_duration'].loc[(data['media_duration']>=150 )&( data['media_duration']<250) ]=-4\n",
    "data['media_duration'].loc[(data['media_duration']>=30 )&( data['media_duration']<150) ]=-5\n",
    "data['media_duration'].loc[(data['media_duration'] <30) &( data['media_duration']>0) ]=-6\n",
    "\n",
    "#diff\n",
    "data['diff'].loc[(data['diff']>=6000) ]=0\n",
    "#data['diff'].loc[(data['diff']>=20000 )&( data['diff']<50000) ]=1\n",
    "#data['diff'].loc[(data['diff']>=10000 )&( data['diff']<20000) ]=2\n",
    "#data['diff'].loc[(data['diff']>=8000 )&( data['diff']<10000) ]=3\n",
    "#data['diff'].loc[(data['diff']>=6000 )&( data['diff']<8000) ]=4\n",
    "data['diff'].loc[(data['diff']>=2000 )&( data['diff']<6000) ]=-5\n",
    "data['diff'].loc[(data['diff']>=1000 )&( data['diff']<2000) ]=-6\n",
    "data['diff'].loc[(data['diff']>=200 )&( data['diff']<1000) ]=-7\n",
    "data['diff'].loc[(data['diff']>=100 )&( data['diff']<200) ]=-8\n",
    "#data['diff'].loc[(data['diff']>=100 )&( data['diff']<300) ]=9\n",
    "data['diff'].loc[(data['diff']>=50 )&( data['diff']<100) ]=-10\n",
    "data['diff'].loc[(data['diff']>=25 )&( data['diff']<50) ]=-11\n",
    "data['diff'].loc[(data['diff']>=10 )&( data['diff']<25) ]=-12\n",
    "data['diff'].loc[(data['diff']<10 ) &( data['diff']>0)]=-13\n",
    "\n",
    "#B\n",
    "#data['B'].loc[(data['B']==0) ]=0\n",
    "data['B'].loc[(data['B']>=0 )&( data['B']<0.5) ]=-1\n",
    "data['B'].loc[(data['B']>=0.5 )&( data['B']<0.7) ]=-2\n",
    "#data['B'].loc[(data['B']>0.4 )&( data['B']<=0.5) ]=3\n",
    "#data['B'].loc[(data['B']>0.5 )&( data['B']<=0.6) ]=4\n",
    "#data['B'].loc[(data['B']>0.6 )&( data['B']<=0.7) ]=5\n",
    "#data['B'].loc[(data['B']>0.7 )&( data['B']<=0.8) ]=6\n",
    "data['B'].loc[(data['B']>=0.7 )&( data['B']<=1) ]=-7\n",
    "#data['B'].loc[(data['B']>0.9 )&( data['B']<1) ]=8\n",
    "#data['B'].loc[(data['B']==1 ) ]=9\n",
    "\n",
    "#C\n",
    "#data['C'].loc[(data['C']==0) ]=0\n",
    "data['C'].loc[(data['C']>=0 )&( data['C']<0.5) ]=-1\n",
    "data['C'].loc[(data['C']>=0.5 )&( data['C']<0.9) ]=-2\n",
    "#data['C'].loc[(data['C']>0.4 )&( data['C']<=0.5) ]=3\n",
    "#data['C'].loc[(data['C']>0.5 )&( data['C']<=0.6) ]=4\n",
    "#data['C'].loc[(data['C']>0.6 )&( data['C']<=0.7) ]=5\n",
    "#data['C'].loc[(data['C']>0.7 )&( data['C']<=0.8) ]=6\n",
    "#data['C'].loc[(data['C']>=0.8 )&( data['C']<=0.9) ]=7\n",
    "data['C'].loc[(data['C']>=0.9 )&( data['C']<=1) ]=-8\n",
    "#data['C'].loc[(data['C']==1 ) ]=9\n",
    "\n",
    "#D\n",
    "#data['D'].loc[(data['D']==0) ]=0\n",
    "data['D'].loc[(data['D']>=0 )&( data['D']<0.5) ]=-1\n",
    "data['D'].loc[(data['D']>=0.5 )&( data['D']<=0.95) ]=-2\n",
    "#data['D'].loc[(data['D']>0.4 )&( data['D']<=0.5) ]=3\n",
    "#data['D'].loc[(data['D']>0.5 )&( data['D']<=0.6) ]=4\n",
    "#data['D'].loc[(data['D']>0.6 )&( data['D']<=0.8) ]=5\n",
    "#data['D'].loc[(data['D']>0.7 )&( data['D']<=0.9) ]=6\n",
    "data['D'].loc[(data['D']>0.95 )&( data['D']<=1) ]=-7\n",
    "#data['D'].loc[(data['D']==1 ) ]=8\n",
    "\n",
    "#E\n",
    "#data['E'].loc[(data['E']==0) ]=0\n",
    "data['E'].loc[(data['E']>0 )&( data['E']<=0.5) ]=-1\n",
    "data['E'].loc[(data['E']>0.5 )&( data['E']<=0.8) ]=-2\n",
    "#data['E'].loc[(data['E']>0.4 )&( data['E']<=0.5) ]=3\n",
    "#data['E'].loc[(data['E']>0.5 )&( data['E']<=0.6) ]=4\n",
    "#data['E'].loc[(data['E']>0.6 )&( data['E']<=0.8) ]=5\n",
    "#data['E'].loc[(data['E']>0.8 )&( data['E']<=0.9) ]=6\n",
    "data['E'].loc[(data['E']>0.8 )&( data['E']<=1) ]=-7\n",
    "#data['E'].loc[(data['E']==1 ) ]=8\n",
    "\n",
    "#F\n",
    "#data['F'].loc[(data['F']==0) ]=0\n",
    "data['F'].loc[(data['F']>=0 )&( data['F']<=0.3) ]=-1\n",
    "data['F'].loc[(data['F']>0.3)&( data['F']<=0.5) ]=-2\n",
    "data['F'].loc[(data['F']>0.5 )&( data['F']<=0.8) ]=-3\n",
    "#data['F'].loc[(data['F']>0.3 )&( data['F']<=0.4) ]=4\n",
    "#data['F'].loc[(data['F']>0.4 )&( data['F']<=0.5) ]=5\n",
    "#data['F'].loc[(data['F']>0.5 )&( data['F']<=0.6) ]=6\n",
    "#data['F'].loc[(data['F']>0.6 )&( data['F']<=0.7) ]=7\n",
    "#data['F'].loc[(data['F']>0.7 )&( data['F']<=0.8) ]=8\n",
    "data['F'].loc[(data['F']>0.8 )&( data['F']<=1) ]=-9\n",
    "#data['F'].loc[(data['F']>0.9 )&( data['F']<1) ]=10\n",
    "#data['F'].loc[(data['F']==1 ) ]=11\n",
    "\n",
    "#G\n",
    "#data['G'].loc[(data['G']==0) ]=0\n",
    "data['G'].loc[(data['G']>=0 )&( data['G']<=0.5) ]=-1\n",
    "data['G'].loc[(data['G']>0.5 )&( data['G']<=0.7) ]=-2\n",
    "data['G'].loc[(data['G']>0.7 )&( data['G']<=0.8) ]=-3\n",
    "#data['G'].loc[(data['G']>0.5 )&( data['G']<=0.6) ]=4\n",
    "#data['G'].loc[(data['G']>0.6 )&( data['G']<=0.7) ]=5\n",
    "#data['G'].loc[(data['G']>0.7 )&( data['G']<=0.8) ]=6\n",
    "#data['G'].loc[(data['G']>0.8 )&( data['G']<=0.9) ]=7\n",
    "data['G'].loc[(data['G']>0.8 )&( data['G']<=1) ]=-8\n",
    "#data['G'].loc[(data['G']==1 ) ]=9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummie1 = pd.get_dummies(data['context_type'], prefix='context_type', prefix_sep='_')\n",
    "dummie2 = pd.get_dummies(data['platform_name'], prefix='platform_name', prefix_sep='_')\n",
    "dummie3 = pd.get_dummies(data['platform_family'], prefix='platform_family', prefix_sep='_')\n",
    "dummie4 = pd.get_dummies(data['listen_type'], prefix='listen_type', prefix_sep='_')\n",
    "dummie5 = pd.get_dummies(data['user_gender'], prefix='user_gender', prefix_sep='_')\n",
    "dummie6 = pd.get_dummies(data['genre_id'], prefix='genre_id', prefix_sep='_')\n",
    "dummie7 = pd.get_dummies(data['album_id'], prefix='album_id', prefix_sep='_')\n",
    "dummie8 = pd.get_dummies(data['release_date'], prefix='album_id', prefix_sep='_')\n",
    "\n",
    "dummie16 = pd.get_dummies(data['media_id'], prefix='media_id', prefix_sep='_')\n",
    "#dummie9 = pd.get_dummies(data['user_id'], prefix='user_id', prefix_sep='_',sparse=True)\n",
    "dummie9 = pd.get_dummies(data['usergencluster'], prefix='usergencluster', prefix_sep='_')\n",
    "dummie10 = pd.get_dummies(data['artist_id'], prefix='artist_id', prefix_sep='_')\n",
    "dummie11 = pd.get_dummies(data['usermedcluster'], prefix='usermedcluster', prefix_sep='_')\n",
    "dummie12= pd.get_dummies(data['useralbcluster'], prefix='useralbcluster', prefix_sep='_')\n",
    "dummie13= pd.get_dummies(data['userartcluster'], prefix='userartcluster', prefix_sep='_')\n",
    "dummie14= pd.get_dummies(data['userdatecluster'], prefix='userdatecluster', prefix_sep='_')\n",
    "dummie15= pd.get_dummies(data['usertimecluster'], prefix='usertimecluster', prefix_sep='_')\n",
    "dummie26= pd.get_dummies(data['useragecluster'], prefix='useragecluster', prefix_sep='_')\n",
    "\n",
    "dummie25= pd.get_dummies(data['user_age'], prefix='user_age', prefix_sep='_')\n",
    "dummie17= pd.get_dummies(data['usercontcluster'], prefix='usercontcluster', prefix_sep='_')\n",
    "dummie18= pd.get_dummies(data['userplatcluster'], prefix='userplatcluster', prefix_sep='_')\n",
    "dummie19= pd.get_dummies(data['userlisttypecluster'], prefix='userlisttypecluster', prefix_sep='_')\n",
    "dummie27= pd.get_dummies(data['userplafamcluster'], prefix='userplafamcluster', prefix_sep='_')\n",
    "dummie28= pd.get_dummies(data['usergendcluster'], prefix='usergendcluster', prefix_sep='_')\n",
    "dummie29= pd.get_dummies(data['genreagecluster'], prefix='genreagecluster', prefix_sep='_')\n",
    "dummie30= pd.get_dummies(data['genrecontcluster'], prefix='genrecontcluster', prefix_sep='_')\n",
    "dummie31= pd.get_dummies(data['genrelistcluster'], prefix='genrelistcluster', prefix_sep='_')\n",
    "dummie32= pd.get_dummies(data['genregendcluster'], prefix='genregendcluster', prefix_sep='_')\n",
    "dummie33= pd.get_dummies(data['genreagedcluster'], prefix='genreagedcluster', prefix_sep='_')\n",
    "dummie34= pd.get_dummies(data['artistgendcluster'], prefix='artistgendcluster', prefix_sep='_')\n",
    "dummie35= pd.get_dummies(data['artistlisttypecluster'], prefix='artistlisttypecluster', prefix_sep='_')\n",
    "dummie36= pd.get_dummies(data['artistlisttypecluster'], prefix='artistlisttypecluster', prefix_sep='_')\n",
    "\n",
    "\n",
    "dummie37= pd.get_dummies(data['B'], prefix='B', prefix_sep='_')\n",
    "dummie38= pd.get_dummies(data['C'], prefix='C', prefix_sep='_')\n",
    "dummie39= pd.get_dummies(data['D'], prefix='D', prefix_sep='_')\n",
    "dummie40= pd.get_dummies(data['E'], prefix='E', prefix_sep='_')\n",
    "dummie41= pd.get_dummies(data['F'], prefix='F', prefix_sep='_')\n",
    "dummie42= pd.get_dummies(data['G'], prefix='G', prefix_sep='_')\n",
    "dummie43= pd.get_dummies(data['diff'], prefix='diff', prefix_sep='_')\n",
    "#dummie24= pd.get_dummies(data['media_duration'], prefix='media_duration', prefix_sep='_')#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>album_id</th>\n",
       "      <th>album_id_1</th>\n",
       "      <th>album_id_freq</th>\n",
       "      <th>...</th>\n",
       "      <th>G_-1.0</th>\n",
       "      <th>diff_-13</th>\n",
       "      <th>diff_-12</th>\n",
       "      <th>diff_-11</th>\n",
       "      <th>diff_-10</th>\n",
       "      <th>diff_-8</th>\n",
       "      <th>diff_-7</th>\n",
       "      <th>diff_-6</th>\n",
       "      <th>diff_-5</th>\n",
       "      <th>diff_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.706600</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>0.626347</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-7.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.706600</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.716894</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.667209</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>34.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1313 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     B    C    D    E    F    G         H  album_id  album_id_1  \\\n",
       "0 -2.0 -1.0 -1.0  0.0 -3.0 -3.0  0.706600        -1          -1   \n",
       "1 -2.0 -8.0 -7.0 -1.0 -3.0 -8.0  0.626347        -1          -1   \n",
       "2 -7.0 -8.0 -7.0 -2.0 -9.0 -3.0  0.706600        -1          -1   \n",
       "3 -2.0 -1.0 -1.0 -2.0 -3.0 -2.0  0.716894        -1          -1   \n",
       "4 -2.0 -2.0 -2.0 -7.0 -9.0 -3.0  0.667209        -1          -1   \n",
       "\n",
       "   album_id_freq   ...    G_-1.0  diff_-13  diff_-12  diff_-11  diff_-10  \\\n",
       "0            1.0   ...         0         0         0         0         0   \n",
       "1            1.0   ...         0         0         0         0         0   \n",
       "2            1.0   ...         0         0         0         0         0   \n",
       "3            1.0   ...         0         0         0         0         0   \n",
       "4           34.0   ...         0         0         0         0         0   \n",
       "\n",
       "   diff_-8  diff_-7  diff_-6  diff_-5  diff_0  \n",
       "0        0        0        0        1       0  \n",
       "1        0        0        0        1       0  \n",
       "2        0        1        0        0       0  \n",
       "3        0        0        0        1       0  \n",
       "4        0        0        0        1       0  \n",
       "\n",
       "[5 rows x 1313 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.concat([data,dummie1,dummie2,dummie3,dummie4,dummie5,dummie6,dummie7,dummie8,dummie9,dummie10,dummie11,dummie12,dummie13,dummie14,dummie15,dummie17,dummie16,dummie18,dummie19,dummie16,dummie25,dummie26,dummie28,dummie29,dummie30,dummie31,dummie32,dummie33,dummie34,dummie35,dummie36,dummie37,dummie38,dummie39,dummie40,dummie41,dummie42,dummie43],axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dummie20' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-6f81bc214cae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mdummie33\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mdummie34\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mdummie20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mdummie25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mdummie26\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dummie20' is not defined"
     ]
    }
   ],
   "source": [
    "del dummie1\n",
    "del dummie2\n",
    "del dummie3\n",
    "del dummie4\n",
    "del dummie5\n",
    "del dummie6\n",
    "del dummie7\n",
    "del dummie8\n",
    "del dummie9\n",
    "del dummie10\n",
    "del dummie11\n",
    "del dummie12\n",
    "del dummie13\n",
    "del dummie14\n",
    "del dummie15\n",
    "del dummie16\n",
    "del dummie17\n",
    "del dummie18\n",
    "del dummie19\n",
    "del dummie30\n",
    "del dummie31\n",
    "del dummie32\n",
    "del dummie33\n",
    "del dummie34\n",
    "del dummie20\n",
    "del dummie25\n",
    "del dummie26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from pyfm import pylibfm\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import numpy as np\n",
    "import scipy.sparse as sps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.asarray(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns.get_loc(\"context_type_-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7578752, 1278)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = data.iloc[:,35:].as_matrix()# assign feature dataframe to predictors removing the target column\n",
    "#target1 = to_categorical(target)# assign target dataframe to y\n",
    "n_cols = predictors.shape[1]\n",
    "predictors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1285"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns.get_loc('B_-1.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3000000x1278 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 167164191 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = sps.csr_matrix(predictors[:3000000].astype(np.float))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating validation dataset of 0.01 of training for adaptive regularization\n",
      "-- Epoch 1\n",
      "Training log loss: 0.48544\n",
      "0:10:01.660641\n"
     ]
    }
   ],
   "source": [
    "fm = pylibfm.FM(verbose=True, task=\"classification\", initial_learning_rate=0.0001, learning_rate_schedule=\"optimal\")\n",
    "start_time = datetime.datetime.now()\n",
    "fm.fit(x[:,20:],y[:3000000])\n",
    "print(datetime.datetime.now()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating validation dataset of 0.01 of training for adaptive regularization\n",
      "-- Epoch 1\n",
      "Training log loss: 0.51327\n",
      "0:03:51.792993\n"
     ]
    }
   ],
   "source": [
    "fm1 = pylibfm.FM(verbose=True, task=\"classification\", initial_learning_rate=0.0001, learning_rate_schedule=\"optimal\")\n",
    "start_time = datetime.datetime.now()\n",
    "fm1.fit(x[:,20:1250],y[:3000000])\n",
    "print(datetime.datetime.now()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = sps.csr_matrix(predictors[7558834:,20:1250].astype(np.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = fm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.53651935,  0.42769682,  0.57127618, ...,  0.50354658,\n",
       "        0.4041672 ,  0.59796232])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(preds, columns=['is_listened'])\n",
    "submission.to_csv('libffm_full_4.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
